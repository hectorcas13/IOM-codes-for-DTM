{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Insert data into an Excel file using Python</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. GENERAL INSTRUCCIONS FOR THIS PYTHON NOTEBOOK TO WORK</h3>\n",
    "<h4>a. We need the following python libraries:</h4>\n",
    "<ul>\n",
    "  <li>pandas</li>\n",
    "  <li>openpyxl</li>\n",
    "  <li>mysql-connector-python</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our libraries\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Path\n",
    "FileName = \"\" # Type the file name\n",
    "path = rf\"\"   # Enter the path where the file is located\n",
    "tab_name_1 = f\"data\"  # Name of the tab with the original data\n",
    "tab_name_2 = f\"family\" # Name of the tab with the family data\n",
    "\n",
    "# Server settings and database\n",
    "server = ''  # Server name\n",
    "database = ''  # db name\n",
    "\n",
    "# String for Windows Authentication\n",
    "conn_str = f\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes;\"\n",
    "\n",
    "# Declare table names\n",
    "table_data = \"\"\n",
    "table_family = \"\"\n",
    "\n",
    "    \n",
    "# List of tables to process\n",
    "tables = [table_data, table_family]\n",
    "\n",
    "# Read the Excel files\n",
    "df_data = pd.read_excel(path,sheet_name=tab_name_1)\n",
    "df_fam = pd.read_excel(path,sheet_name=tab_name_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>CLEANING OUT THE DATA FROM THE EXCEL</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_excel(path_to_excel, the_tab, variable_df):\n",
    "    for columna in variable_df.columns:\n",
    "        col_data = variable_df[columna]\n",
    "        \n",
    "        # Detectar columna completamente vac√≠a (todo NaN o strings vac√≠os)\n",
    "        if col_data.dropna().empty or (col_data.dropna() == '').all():\n",
    "            variable_df[columna] = 'Null'\n",
    "        elif col_data.dtype == 'object':\n",
    "            variable_df[columna] = col_data.fillna('Null')\n",
    "        elif np.issubdtype(col_data.dtype, np.number):\n",
    "            variable_df[columna] = pd.to_numeric(col_data, errors='coerce').fillna(-9999)\n",
    "        elif np.issubdtype(col_data.dtype, np.datetime64):\n",
    "            variable_df[columna] = col_data.fillna(pd.Timestamp('1900-01-01'))\n",
    "\n",
    "    with pd.ExcelWriter(path_to_excel, mode='a', if_sheet_exists='replace', engine='openpyxl') as writer:\n",
    "        variable_df.to_excel(writer, index=False, sheet_name=the_tab)\n",
    "    \n",
    "    print(f\"The Excel file {path_to_excel} has been cleaned up\")\n",
    "\n",
    "# Ejecutamos la consulta\n",
    "clean_data_excel(path,tab_name_1,df_data)\n",
    "clean_data_excel(path,tab_name_2,df_fam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>4. Connecting Jupyer Notebook with MySQL Server Database</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The following connection uses window's authentication method which is the method utilized for connecting to the database</p>\n",
    "<p>If we receive the following message: <b>You are now connected to MySQL Server Database</b>, It means the connection is successful, and we are ready to insert the data. We can use the following code below to insert the data. In this step we make sure we are authorized to connect successfully to the database.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    # test connection\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    print(\"You are now connected to MySQL Server Database\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(\"Houston! there is an error!\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>5. We create the table</h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infer_sql_type(series, col_name):\n",
    "    \"\"\"Infers the SQL data type based on a pandas series.\"\"\"\n",
    "    if series.dropna().empty or (series.dropna() == '').all():\n",
    "        return \"VARCHAR(100)\"  # Campo vac√≠o o solo contiene valores vac√≠os\n",
    "    if pd.api.types.is_integer_dtype(series):\n",
    "        return \"INTEGER\"\n",
    "    elif pd.api.types.is_float_dtype(series):\n",
    "        return \"REAL\"\n",
    "    elif pd.api.types.is_datetime64_any_dtype(series):\n",
    "        return \"DATETIME\" if series.dt.time.nunique() > 1 else \"DATE\"\n",
    "    else:\n",
    "        max_len = series.astype(str).str.len().max()\n",
    "        return f\"VARCHAR({max_len})\"\n",
    "\n",
    "def create_table_peru(df, table, conn_str):\n",
    "    # Infer data types (for all except forced _id)\n",
    "    column_types = {\n",
    "        col: infer_sql_type(df[col], col) for col in df.columns\n",
    "    }\n",
    "\n",
    "    columns_sql = []\n",
    "    primary_key_sql = \"\"\n",
    "\n",
    "    for col, dtype in column_types.items():\n",
    "        if col.lower() == \"_id\":\n",
    "            columns_sql.append(f'\"{col}\" BIGINT')\n",
    "            primary_key_sql = f'PRIMARY KEY(\"{col}\")'\n",
    "        else:\n",
    "            columns_sql.append(f'\"{col}\" {dtype}')\n",
    "\n",
    "    # If no _id, insert artificial ID column\n",
    "    if '_id' not in df.columns and 'ID' not in df.columns:\n",
    "        columns_sql.insert(0, '\"ID\" BIGINT IDENTITY(1,1) PRIMARY KEY NOT NULL')\n",
    "\n",
    "    create_table_sql = f\"CREATE TABLE {table} ({', '.join(columns_sql)}\"\n",
    "    if primary_key_sql:\n",
    "        create_table_sql += f\", {primary_key_sql}\"\n",
    "    create_table_sql += \");\"\n",
    "\n",
    "    # Connect and execute\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"‚úÖ Table '{table}' successfully created.\")\n",
    "    print(\"üîß SQL:\", create_table_sql)\n",
    "\n",
    "# Usage\n",
    "create_table_peru(df_data, table_data, conn_str)\n",
    "create_table_peru(df_fam, table_family, conn_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>6. We cross filter the data to see what we are inserting in</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_count_excel(tab):\n",
    "    # Upload files to Excel with the tab name\n",
    "    t = pd.read_excel(path, sheet_name=f\"{tab}\")\n",
    "\n",
    "    try:\n",
    "        # Mostrar los datos resultantes en formato tabular\n",
    "        print(f\"First five rows filtered for the tab {tab}:\")\n",
    "        print(tabulate(t.head(50), headers='keys', tablefmt='grid'))\n",
    "\n",
    "        row_count = len(t)\n",
    "        print(f\"\\nTotal number of rows that will be inserted in the DB for {tab} is: {row_count}\")\n",
    "        print(\"\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Column's related error: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Houston, we got a problem!: {e}\")\n",
    "\n",
    "read_count_excel(tab_name_1)\n",
    "read_count_excel(tab_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting data into MYSQL Server\n",
    "\n",
    "def insert_data_from_excel(conn_str, excel_path, sheet_name, table_name):\n",
    "    # Leer la hoja espec√≠fica del Excel\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "\n",
    "    # Conectar a la base de datos\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Obtener informaci√≥n de las columnas de la tabla en SQL Server\n",
    "    column_info_sql = f\"\"\"\n",
    "        SELECT COLUMN_NAME, CHARACTER_MAXIMUM_LENGTH\n",
    "        FROM INFORMATION_SCHEMA.COLUMNS\n",
    "        WHERE TABLE_NAME = '{table_name}'\n",
    "    \"\"\"\n",
    "    cursor.execute(column_info_sql)\n",
    "    column_info = {row.COLUMN_NAME: row.CHARACTER_MAXIMUM_LENGTH for row in cursor.fetchall() if row.CHARACTER_MAXIMUM_LENGTH}\n",
    "\n",
    "    truncated_columns = []\n",
    "\n",
    "    # Truncar valores que exceden el l√≠mite de la base de datos\n",
    "    for col, max_length in column_info.items():\n",
    "        if col in df.columns:\n",
    "            truncated_values = df[col].astype(str).apply(lambda x: x if len(x) <= max_length else x[:max_length])\n",
    "            if not df[col].equals(truncated_values):  # Detecta si hubo truncamiento\n",
    "                truncated_columns.append(col)\n",
    "                print(f\"‚ö†Ô∏è Columna '{col}' truncada. Valores originales vs truncados:\")\n",
    "                for orig, trunc in zip(df[col], truncated_values):\n",
    "                    if orig != trunc:\n",
    "                        print(f\"  - Original: {orig}\")\n",
    "                        print(f\"  - Truncado: {trunc}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "            df[col] = truncated_values\n",
    "\n",
    "    # Crear la sentencia SQL para inserci√≥n\n",
    "    columns = \", \".join([f\"[{col}]\" for col in df.columns])\n",
    "    placeholders = \", \".join([\"?\" for _ in df.columns])\n",
    "    insert_sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "    # Insertar los datos fila por fila\n",
    "    for row in df.itertuples(index=False, name=None):\n",
    "        cursor.execute(insert_sql, row)\n",
    "\n",
    "    # Confirmar cambios y cerrar conexi√≥n\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"‚úÖ Datos insertados en la tabla '{table_name}' con √©xito.\")\n",
    "    if truncated_columns:\n",
    "        print(f\"‚ö†Ô∏è Se truncaron las siguientes columnas: {', '.join(truncated_columns)}\")\n",
    "\n",
    "# Uso del c√≥digo\n",
    "insert_data_from_excel(conn_str, path, tab_name_1, table_data)\n",
    "insert_data_from_excel(conn_str, path, tab_name_2, table_family)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>8. Cleaning the data from the SQL Server to remove -9999, 1900-01-01, \"*\", and NULL text values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING OUT THE TABLES 1\n",
    "try:\n",
    "    # Establish the connection\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Successfully connected to the database.\")\n",
    "\n",
    "    # Function to generate the SQL query to clean the table\n",
    "    def change_to_nulls(table_data):\n",
    "        \n",
    "        # SQL query to clean the table\n",
    "        nulls_query = f\"\"\"\n",
    "            DECLARE @tableName NVARCHAR(MAX) = '{table_data}'\n",
    "            DECLARE @sql NVARCHAR(MAX) = ''\n",
    "\n",
    "            -- Generar el SQL din√°mico para actualizar columnas de tipo texto\n",
    "            SELECT @sql = STRING_AGG(\n",
    "                'UPDATE ' + @tableName + ' SET [' + COLUMN_NAME + '] = NULL WHERE [' + COLUMN_NAME + '] = ''*'';',\n",
    "                ' '\n",
    "            )\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = @tableName\n",
    "            AND DATA_TYPE IN ('char', 'varchar', 'nchar', 'nvarchar', 'text', 'ntext')\n",
    "\n",
    "            -- Ejecutar el SQL din√°mico\n",
    "            EXEC sp_executesql @sql\n",
    "\n",
    "            \n",
    "            -- Generar el SQL din√°mico para actualizar columnas de tipo fecha\n",
    "            SELECT @sql = STRING_AGG(\n",
    "                'UPDATE ' + @tableName + ' SET [' + COLUMN_NAME + '] = NULL WHERE [' + COLUMN_NAME + '] = ''1900-01-01'';',\n",
    "                ' '\n",
    "            )\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = @tableName\n",
    "            AND DATA_TYPE IN ('date', 'datetime', 'datetime2', 'smalldatetime')\n",
    "\n",
    "            -- Ejecutar el SQL din√°mico\n",
    "            EXEC sp_executesql @sql\n",
    "\n",
    "        \"\"\"\n",
    "        return nulls_query\n",
    "\n",
    "    # Iterate through the tables and execute the cleaning process\n",
    "    for table in tables:\n",
    "        query = change_to_nulls(table)\n",
    "        cursor.execute(query)\n",
    "        print(f\"Table {table} has been cleaned up.\")\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    # Handle errors during connection or execution\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the connection is closed\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING OUT THE TABLES 2\n",
    "try:\n",
    "    # Establish the connection\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Successfully connected to the database.\")\n",
    "\n",
    "    # Function to generate the SQL query to clean the table\n",
    "    def change_to_nulls2(table_data):\n",
    "        \n",
    "        # SQL query to clean the table\n",
    "        nulls_query = f\"\"\"\n",
    "            DECLARE @tableName NVARCHAR(MAX) = '{table_data}'\n",
    "            DECLARE @sql NVARCHAR(MAX);\n",
    "\n",
    "                        -- Ejecutar el SQL din√°mico\n",
    "            EXEC sp_executesql @sql\n",
    "\n",
    "            SELECT @sql = STRING_AGG(\n",
    "            CONCAT(\n",
    "                'UPDATE ', @tableName, ' ',\n",
    "                'SET ', QUOTENAME(c.name), ' = NULL ',\n",
    "                'WHERE ', QUOTENAME(c.name), ' = ''Null'';'\n",
    "            ), CHAR(13) + CHAR(10)\n",
    "            )\n",
    "            FROM sys.columns c\n",
    "            WHERE c.object_id = OBJECT_ID(@tableName)\n",
    "            AND c.system_type_id IN (167, 175, 231);\n",
    "            \n",
    "            EXEC sp_executesql @sql;\n",
    "\n",
    "            \"\"\"\n",
    "        return nulls_query\n",
    "\n",
    "    # Iterate through the tables and execute the cleaning process\n",
    "    for table in tables:\n",
    "        query = change_to_nulls2(table)\n",
    "        cursor.execute(query)\n",
    "        print(f\"Table {table} has been cleaned up.\")\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    # Handle errors during connection or execution\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the connection is closed\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING OUT THE TABLES 3\n",
    "try:\n",
    "    # Establish the connection\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Successfully connected to the database.\")\n",
    "\n",
    "    # Function to generate the SQL query to clean the table\n",
    "    def change_to_nulls3(table_data):\n",
    "        \n",
    "        # SQL query to clean the table\n",
    "        nulls_query = f\"\"\"\n",
    "            DECLARE @tableName NVARCHAR(MAX) = '{table_data}'\n",
    "            DECLARE @sql NVARCHAR(MAX) = ''\n",
    "\n",
    "            -- Generar el SQL din√°mico para actualizar columnas num√©ricas\n",
    "            SELECT @sql = STRING_AGG(\n",
    "                'UPDATE ' + @tableName + ' SET [' + COLUMN_NAME + '] = NULL WHERE [' + COLUMN_NAME + '] = -9999;',\n",
    "                ' '\n",
    "            )\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = @tableName\n",
    "            AND DATA_TYPE IN ('int', 'bigint', 'smallint', 'tinyint', 'decimal', 'numeric', 'float', 'real')\n",
    "\n",
    "            -- Ejecutar el SQL din√°mico\n",
    "            EXEC sp_executesql @sql\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "        return nulls_query\n",
    "\n",
    "    # Iterate through the tables and execute the cleaning process\n",
    "    for table in tables:\n",
    "        query = change_to_nulls3(table)\n",
    "        cursor.execute(query)\n",
    "        print(f\"Table {table} has been cleaned up.\")\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    # Handle errors during connection or execution\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the connection is closed\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING OUT THE TABLES 4\n",
    "try:\n",
    "    # Establish the connection\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Successfully connected to the database.\")\n",
    "\n",
    "    # Function to generate the SQL query to clean the table\n",
    "    def change_to_nulls4(table_data):\n",
    "        \n",
    "        # SQL query to clean the table\n",
    "        nulls_query = f\"\"\"\n",
    "\n",
    "            DECLARE @tableName NVARCHAR(MAX) = '{table_data}'\n",
    "            DECLARE @sql NVARCHAR(MAX) = ''\n",
    "\n",
    "            -- Generar el SQL din√°mico para actualizar columnas de tipo texto\n",
    "            SELECT @sql = STRING_AGG(\n",
    "                'UPDATE ' + @tableName + ' SET [' + COLUMN_NAME + '] = NULL WHERE [' + COLUMN_NAME + '] = ''-9999'';',\n",
    "                ' '\n",
    "            )\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = @tableName\n",
    "            AND DATA_TYPE IN ('char', 'varchar', 'nchar', 'nvarchar', 'text', 'ntext')\n",
    "\n",
    "            -- Ejecutar el SQL din√°mico\n",
    "            EXEC sp_executesql @sql\n",
    "\n",
    "            \"\"\"\n",
    "        return nulls_query\n",
    "\n",
    "    # Iterate through the tables and execute the cleaning process\n",
    "    for table in tables:\n",
    "        query = change_to_nulls4(table)\n",
    "        cursor.execute(query)\n",
    "        print(f\"Table {table} has been cleaned up.\")\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    # Handle errors during connection or execution\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the connection is closed\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
