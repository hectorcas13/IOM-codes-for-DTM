{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Insert data into an Excel file using Python</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Declaring our variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our libraries\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from tabulate import tabulate\n",
    "\n",
    "country = f\"\" # Insert name of the country to upload\n",
    "country_iso = f\"\" # Insert ISO3 code of the country to upload\n",
    "\n",
    "# Path\n",
    "FileName = f\"\" \n",
    "path = rf\"\"        # Enter the location of the file\n",
    "tab_name_1 = f\"\".  # Entet the tab name of the file where the FMR data is\n",
    "\n",
    "\n",
    "# Server settings and database\n",
    "server = \"\"  # Server name\n",
    "database = f\"\"  # db name\n",
    "\n",
    "# String for Windows Authentication\n",
    "conn_str = f\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes;\"\n",
    "\n",
    "# Declare table names+\n",
    "table_name_data = f\"\"\n",
    "\n",
    "\n",
    "# Read the Excel files\n",
    "df_data = pd.read_excel(path, sheet_name=tab_name_1)\n",
    "    \n",
    "# List of tables to process\n",
    "tables = [table_name_data]\n",
    "tabs = [tab_name_1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Connecting Jupyer Notebook with MySQL Server Database</h3>\n",
    "<p>Here we make sure we have a succesfull conection to the database server</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CONNECTION\n",
    "try:\n",
    "    # test connection\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    print(\"You are now connected to MySQL Server Database\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(\"Houston! We have an error!\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. In this step we clean the data for the excel</b></h3>\n",
    "<p>4.1 The code below will make null every text value that is blank in the excel.</p>\n",
    "<p>4.2 The code below will add a 1900-01-01 to every date value that is blank in the excel.</p>\n",
    "<p>4.4 The code below will add -9999 every number value that is blank in the excel.</p>\n",
    "<p>4.5 The Excel file must be closed for this to work.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_excel(path_to_excel, the_tab, variable_df):\n",
    "    for columna in variable_df.columns:\n",
    "        col_data = variable_df[columna]\n",
    "        \n",
    "        # Detectar columna completamente vac√≠a (todo NaN o strings vac√≠os)\n",
    "        if col_data.dropna().empty or (col_data.dropna() == '').all():\n",
    "            variable_df[columna] = 'Null'\n",
    "        elif col_data.dtype == 'object':\n",
    "            variable_df[columna] = col_data.fillna('Null')\n",
    "        elif np.issubdtype(col_data.dtype, np.number):\n",
    "            variable_df[columna] = pd.to_numeric(col_data, errors='coerce').fillna(-9999)\n",
    "        elif np.issubdtype(col_data.dtype, np.datetime64):\n",
    "            variable_df[columna] = col_data.fillna(pd.Timestamp('1900-01-01'))\n",
    "\n",
    "    with pd.ExcelWriter(path_to_excel, mode='a', if_sheet_exists='replace', engine='openpyxl') as writer:\n",
    "        variable_df.to_excel(writer, index=False, sheet_name=the_tab)\n",
    "    \n",
    "    print(f\"The Excel file {path_to_excel} has been cleaned up\")\n",
    "\n",
    "# Ejecutamos la consulta\n",
    "clean_data_excel(path,tab_name_1,df_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5. Creation of the tables Families filtering by</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infer_sql_type(series, col_name):\n",
    "    \"\"\"Infers the SQL data type based on a pandas series.\"\"\"\n",
    "    if series.dropna().empty or (series.dropna() == '').all():\n",
    "        return \"VARCHAR(100)\"  # Campo vac√≠o o solo contiene valores vac√≠os\n",
    "    if pd.api.types.is_integer_dtype(series):\n",
    "        return \"INTEGER\"\n",
    "    elif pd.api.types.is_float_dtype(series):\n",
    "        return \"REAL\"\n",
    "    elif pd.api.types.is_datetime64_any_dtype(series):\n",
    "        return \"DATETIME\" if series.dt.time.nunique() > 1 else \"DATE\"\n",
    "    else:\n",
    "        max_len = series.astype(str).str.len().max()\n",
    "        return f\"VARCHAR({max_len})\"\n",
    "\n",
    "def create_table_from_dataframe(df, table, conn_str):\n",
    "    # Infer data types (for all except forced _id)\n",
    "    column_types = {\n",
    "        col: infer_sql_type(df[col], col) for col in df.columns\n",
    "    }\n",
    "\n",
    "    columns_sql = []\n",
    "    primary_key_sql = \"\"\n",
    "\n",
    "    for col, dtype in column_types.items():\n",
    "        if col.lower() == \"_id\":\n",
    "            columns_sql.append(f'\"{col}\" INT')\n",
    "            primary_key_sql = f'PRIMARY KEY(\"{col}\")'\n",
    "        else:\n",
    "            columns_sql.append(f'\"{col}\" {dtype}')\n",
    "\n",
    "    # If no _id, insert artificial ID column\n",
    "    if '_id' not in df.columns and 'ID' not in df.columns:\n",
    "        columns_sql.insert(0, '\"id_fmp\" INT IDENTITY(1,1) PRIMARY KEY NOT NULL')\n",
    "\n",
    "    create_table_sql = f\"CREATE TABLE {table} ({', '.join(columns_sql)}\"\n",
    "    if primary_key_sql:\n",
    "        create_table_sql += f\", {primary_key_sql}\"\n",
    "    create_table_sql += \");\"\n",
    "\n",
    "    # Connect and execute\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"‚úÖ Table '{table}' successfully created.\")\n",
    "    print(\"üîß SQL:\", create_table_sql)\n",
    "    \n",
    "create_table_from_dataframe(df_data, table_name_data, conn_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>6. We display in a tabulation the tables to be inserted, we count them so we can compare them with the Excel file shared to us by the mission</b></h3>\n",
    "<p>6.1. We create the a function to read the data of every city and count how many rows they have, then we can the function.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_count_excel(tab):\n",
    "    # Upload files to Excel with the tab name\n",
    "    t = pd.read_excel(path, sheet_name=f\"{tab}\")\n",
    "\n",
    "    try:\n",
    "        # Mostrar los datos resultantes en formato tabular\n",
    "        print(f\"First five rows filtered for the tab {tab}:\")\n",
    "        print(tabulate(t.head(5), headers='keys', tablefmt='grid'))\n",
    "\n",
    "        row_count = len(t)\n",
    "        print(f\"\\nTotal number of rows that will be inserted in the DB for {tab} is: {row_count}\")\n",
    "        print(\"\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"Column's related error: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Houston, we got a problem!: {e}\")\n",
    "\n",
    "for tab in tabs:\n",
    "    read_count_excel(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7. Inserting the values of the rows into the Excel file</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting data into MYSQL Server\n",
    "\n",
    "def insert_data_from_excel(conn_str, excel_path, sheet_name, table_name):\n",
    "    # Leer la hoja espec√≠fica del Excel\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "\n",
    "    # Conectar a la base de datos\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Obtener informaci√≥n de las columnas de la tabla en SQL Server\n",
    "    column_info_sql = f\"\"\"\n",
    "        SELECT COLUMN_NAME, CHARACTER_MAXIMUM_LENGTH\n",
    "        FROM INFORMATION_SCHEMA.COLUMNS\n",
    "        WHERE TABLE_NAME = '{table_name}'\n",
    "    \"\"\"\n",
    "    cursor.execute(column_info_sql)\n",
    "    column_info = {row.COLUMN_NAME: row.CHARACTER_MAXIMUM_LENGTH for row in cursor.fetchall() if row.CHARACTER_MAXIMUM_LENGTH}\n",
    "\n",
    "    truncated_columns = []\n",
    "\n",
    "    # Truncar valores que exceden el l√≠mite de la base de datos\n",
    "    for col, max_length in column_info.items():\n",
    "        if col in df.columns:\n",
    "            truncated_values = df[col].astype(str).apply(lambda x: x if len(x) <= max_length else x[:max_length])\n",
    "            if not df[col].equals(truncated_values):  # Detecta si hubo truncamiento\n",
    "                truncated_columns.append(col)\n",
    "                print(f\"‚ö†Ô∏è Columna '{col}' truncada. Valores originales vs truncados:\")\n",
    "                for orig, trunc in zip(df[col], truncated_values):\n",
    "                    if orig != trunc:\n",
    "                        print(f\"  - Original: {orig}\")\n",
    "                        print(f\"  - Truncado: {trunc}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "            df[col] = truncated_values\n",
    "\n",
    "    # Crear la sentencia SQL para inserci√≥n\n",
    "    columns = \", \".join([f\"[{col}]\" for col in df.columns])\n",
    "    placeholders = \", \".join([\"?\" for _ in df.columns])\n",
    "    insert_sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "    # Insertar los datos fila por fila\n",
    "    for row in df.itertuples(index=False, name=None):\n",
    "        cursor.execute(insert_sql, row)\n",
    "\n",
    "    # Confirmar cambios y cerrar conexi√≥n\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"‚úÖ Datos insertados en la tabla '{table_name}' con √©xito.\")\n",
    "    if truncated_columns:\n",
    "        print(f\"‚ö†Ô∏è Se truncaron las siguientes columnas: {', '.join(truncated_columns)}\")\n",
    "\n",
    "\n",
    "# Uso del c√≥digo\n",
    "insert_data_from_excel(conn_str, path, tab_name_1, table_name_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>8. Cleaning the data from the SQL Server to remove -9999, 1900-01-01, \"*\", and NULL text values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING OUT THE TABLES 1\n",
    "try:\n",
    "    # Establish the connection\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Successfully connected to the database.\")\n",
    "\n",
    "    # Function to generate the SQL query to clean the table\n",
    "    def change_to_nulls(table_data):\n",
    "        \n",
    "        # SQL query to clean the table\n",
    "        nulls_query = f\"\"\"\n",
    "            DECLARE @tableName NVARCHAR(MAX) = '{table_data}'\n",
    "            DECLARE @sql NVARCHAR(MAX) = ''\n",
    "\n",
    "            -- Generar el SQL din√°mico para actualizar columnas de tipo texto\n",
    "            SELECT @sql = STRING_AGG(\n",
    "                'UPDATE ' + @tableName + ' SET [' + COLUMN_NAME + '] = NULL WHERE [' + COLUMN_NAME + '] = ''*'';',\n",
    "                ' '\n",
    "            )\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = @tableName\n",
    "            AND DATA_TYPE IN ('char', 'varchar', 'nchar', 'nvarchar', 'text', 'ntext')\n",
    "\n",
    "            -- Ejecutar el SQL din√°mico\n",
    "            EXEC sp_executesql @sql\n",
    "\n",
    "            \n",
    "            -- Generar el SQL din√°mico para actualizar columnas de tipo fecha\n",
    "            SELECT @sql = STRING_AGG(\n",
    "                'UPDATE ' + @tableName + ' SET [' + COLUMN_NAME + '] = NULL WHERE [' + COLUMN_NAME + '] = ''1900-01-01'';',\n",
    "                ' '\n",
    "            )\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = @tableName\n",
    "            AND DATA_TYPE IN ('date', 'datetime', 'datetime2', 'smalldatetime')\n",
    "\n",
    "            -- Ejecutar el SQL din√°mico\n",
    "            EXEC sp_executesql @sql\n",
    "\n",
    "        \"\"\"\n",
    "        return nulls_query\n",
    "\n",
    "    # Iterate through the tables and execute the cleaning process\n",
    "    for table in tables:\n",
    "        query = change_to_nulls(table)\n",
    "        cursor.execute(query)\n",
    "        print(f\"Table {table} has been cleaned up.\")\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    # Handle errors during connection or execution\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the connection is closed\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING OUT THE TABLES 2\n",
    "try:\n",
    "    # Establish the connection\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Successfully connected to the database.\")\n",
    "\n",
    "    # Function to generate the SQL query to clean the table\n",
    "    def change_to_nulls2(table_data):\n",
    "        \n",
    "        # SQL query to clean the table\n",
    "        nulls_query = f\"\"\"\n",
    "            DECLARE @tableName NVARCHAR(MAX) = '{table_data}'\n",
    "            DECLARE @sql NVARCHAR(MAX);\n",
    "\n",
    "                        -- Ejecutar el SQL din√°mico\n",
    "            EXEC sp_executesql @sql\n",
    "\n",
    "            SELECT @sql = STRING_AGG(\n",
    "            CONCAT(\n",
    "                'UPDATE ', @tableName, ' ',\n",
    "                'SET ', QUOTENAME(c.name), ' = NULL ',\n",
    "                'WHERE ', QUOTENAME(c.name), ' = ''Null'';'\n",
    "            ), CHAR(13) + CHAR(10)\n",
    "            )\n",
    "            FROM sys.columns c\n",
    "            WHERE c.object_id = OBJECT_ID(@tableName)\n",
    "            AND c.system_type_id IN (167, 175, 231);\n",
    "            \n",
    "            EXEC sp_executesql @sql;\n",
    "\n",
    "            \"\"\"\n",
    "        return nulls_query\n",
    "\n",
    "    # Iterate through the tables and execute the cleaning process\n",
    "    for table in tables:\n",
    "        query = change_to_nulls2(table)\n",
    "        cursor.execute(query)\n",
    "        print(f\"Table {table} has been cleaned up.\")\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    # Handle errors during connection or execution\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the connection is closed\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING OUT THE TABLES 3\n",
    "try:\n",
    "    # Establish the connection\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Successfully connected to the database.\")\n",
    "\n",
    "    # Function to generate the SQL query to clean the table\n",
    "    def change_to_nulls3(table_data):\n",
    "        \n",
    "        # SQL query to clean the table\n",
    "        nulls_query = f\"\"\"\n",
    "            DECLARE @tableName NVARCHAR(MAX) = '{table_data}'\n",
    "            DECLARE @sql NVARCHAR(MAX) = ''\n",
    "\n",
    "            -- Generar el SQL din√°mico para actualizar columnas num√©ricas\n",
    "            SELECT @sql = STRING_AGG(\n",
    "                'UPDATE ' + @tableName + ' SET [' + COLUMN_NAME + '] = NULL WHERE [' + COLUMN_NAME + '] = -9999;',\n",
    "                ' '\n",
    "            )\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = @tableName\n",
    "            AND DATA_TYPE IN ('int', 'bigint', 'smallint', 'tinyint', 'decimal', 'numeric', 'float', 'real')\n",
    "\n",
    "            -- Ejecutar el SQL din√°mico\n",
    "            EXEC sp_executesql @sql\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "        return nulls_query\n",
    "\n",
    "    # Iterate through the tables and execute the cleaning process\n",
    "    for table in tables:\n",
    "        query = change_to_nulls3(table)\n",
    "        cursor.execute(query)\n",
    "        print(f\"Table {table} has been cleaned up.\")\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    # Handle errors during connection or execution\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the connection is closed\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING OUT THE TABLES 4\n",
    "try:\n",
    "    # Establish the connection\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Successfully connected to the database.\")\n",
    "\n",
    "    # Function to generate the SQL query to clean the table\n",
    "    def change_to_nulls4(table_data):\n",
    "        \n",
    "        # SQL query to clean the table\n",
    "        nulls_query = f\"\"\"\n",
    "\n",
    "            DECLARE @tableName NVARCHAR(MAX) = '{table_data}'\n",
    "            DECLARE @sql NVARCHAR(MAX) = ''\n",
    "\n",
    "            -- Generar el SQL din√°mico para actualizar columnas de tipo texto\n",
    "            SELECT @sql = STRING_AGG(\n",
    "                'UPDATE ' + @tableName + ' SET [' + COLUMN_NAME + '] = NULL WHERE [' + COLUMN_NAME + '] = ''-9999'';',\n",
    "                ' '\n",
    "            )\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = @tableName\n",
    "            AND DATA_TYPE IN ('char', 'varchar', 'nchar', 'nvarchar', 'text', 'ntext')\n",
    "\n",
    "            -- Ejecutar el SQL din√°mico\n",
    "            EXEC sp_executesql @sql\n",
    "\n",
    "            \"\"\"\n",
    "        return nulls_query\n",
    "\n",
    "    # Iterate through the tables and execute the cleaning process\n",
    "    for table in tables:\n",
    "        query = change_to_nulls4(table)\n",
    "        cursor.execute(query)\n",
    "        print(f\"Table {table} has been cleaned up.\")\n",
    "        # Commit the changes\n",
    "        conn.commit()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    # Handle errors during connection or execution\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the connection is closed\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
